---

authors:
- Alexander Amini
- Igor Gilitschenski
- Jacob Philips
- Julia Moseyko
- Rohan Banerjee
- Sertac Karaman
- Daniela Rus
publishdate : "2019-12-02"
date : "2020-04-01T00:00:00Z"

publication_types : ["article-journal"]
publication_short : "*RA-L*"
publication : "*IEEE Robotics and Automation Letters*"
title : "Learning Robust Control Policies for End-to-End Autonomous Driving from Data-Driven Simulation"

abstract: In this work, we present a data-driven simulation and training engine capable of learning end-to-end autonomous vehicle control policies using only sparse rewards. By leveraging real, human-collected trajectories through an environment, we render novel training data that allows virtual agents to drive along a continuum of new local trajectories consistent with the road appearance and semantics, each with a different view of the scene. We demonstrate the ability of policies learned within our simulator to generalize to and navigate in previously unseen real-world roads, without access to any human control labels during training. Our results validate the learned policy onboard a full-scale autonomous vehicle, including in previously un-encountered scenarios, such as new roads and novel, complex, near-crash situations. Our methods are scalable, leverage reinforcement learning, and apply broadly to situations requiring effective perception and robust operation in the physical world.

url_pdf: "publication/202004-ral-vista/ral20-vista.pdf"
url_video: "https://www.youtube.com/watch?v=YgFlMnQmASw"
url_project: "https://vista.csail.mit.edu/"
url_code: "https://github.com/vista-simulator/vista"

featured: false
---
